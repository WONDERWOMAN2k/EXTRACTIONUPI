# -*- coding: utf-8 -*-
"""extractioi.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VVmIk2L9xrIJQNix7K2wCv41ynwxCjih
"""

# üì¶ INSTALL LIBRARIES
!pip install pdfplumber pandas

# üìÇ UPLOAD PDF FILE
from google.colab import files
uploaded = files.upload()

import pdfplumber
import pandas as pd
import re
import io


# üß† PDF Extraction Function
def extract_upi_data_from_pdf(file_stream):
    transactions = []

    with pdfplumber.open(file_stream) as pdf:
        for page in pdf.pages:
            text = page.extract_text()
            lines = text.split('\n')

            for line in lines:
                # Mock format: 01-04-2024 10:22 Flipkart Rs.1,234.00 Shopping
                match = re.match(r'(\d{2}-\d{2}-\d{4})\s+(\d{2}:\d{2})\s+(.+?)\s+Rs\.?([\d,]+\.\d{2})\s+(.+)', line)
                if match:
                    date, time, receiver, amount, description = match.groups()
                    amount = float(amount.replace(',', ''))
                    transactions.append({
                        'Date': date,
                        'Time': time,
                        'Receiver': receiver.strip(),
                        'Amount': amount,
                        'Description': description.strip(),
                        'Category': 'Uncategorized'
                    })

    df = pd.DataFrame(transactions)
    return df

# üèÉ‚Äç‚ôÄÔ∏è Run the parser
for filename in uploaded.keys():
    with io.BytesIO(uploaded[filename]) as file_stream:
        df = extract_upi_data_from_pdf(file_stream)
        df.to_csv("transactions.csv", index=False)
        print("‚úÖ Extracted data saved to transactions.csv")
        display(df.head())

import pandas as pd

# Sample DataFrame (replace this with your actual DataFrame)
data = {
    'Description': ['Purchase at Store A', 'Purchase at Store B', 'Payment received', 'Purchase at Store C'],
    'Amount': [150, 200, 500, 100]
}

# Create the DataFrame
df = pd.DataFrame(data)

# Strip any leading/trailing spaces in column names
df.columns = df.columns.str.strip()

# Define the categorization function
def categorize_transaction(description):
    if 'Store' in description:
        return 'Purchase'
    elif 'Payment' in description:
        return 'Payment'
    else:
        return 'Other'

# Check if 'Description' column exists
if 'Description' in df.columns:
    # Apply the categorization function to the 'Description' column
    df['Category'] = df['Description'].apply(categorize_transaction)
else:
    print("Column 'Description' not found!")

# Display the DataFrame
print(df)

import pandas as pd

# Sample DataFrame (replace with your actual DataFrame)
data = {
    'Description': ['Swiggy order', 'Amazon purchase', 'Uber ride', 'Bigbasket groceries', 'Recharge prepaid', 'Received salary'],
    'Amount': [150, 200, 300, 100, 50, 500]
}

# Create the DataFrame
df = pd.DataFrame(data)

# Strip any leading/trailing spaces in column names (if any)
df.columns = df.columns.str.strip()

# üîç Auto-categorize based on description keywords
def categorize_transaction(description):
    description = description.lower()
    if "swiggy" in description or "zomato" in description:
        return "Food"
    elif "amazon" in description or "flipkart" in description:
        return "Shopping"
    elif "uber" in description or "ola" in description:
        return "Transport"
    elif "bigbasket" in description:
        return "Groceries"
    elif "recharge" in description:
        return "Utilities"
    elif "cashback" in description:
        return "Rewards"
    elif "received" in description:
        return "Income"
    else:
        return "Others"

# Check if 'Description' column exists before applying
if 'Description' in df.columns:
    # Apply the categorization function to the 'Description' column
    df['Category'] = df['Description'].apply(categorize_transaction)
else:
    print("Column 'Description' not found!")

# Display the DataFrame
print(df.head())

!pip install streamlit

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import streamlit as st
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.preprocessing import LabelEncoder

# Sample DataFrame (replace with your actual DataFrame)
data = {
    'Description': ['Swiggy order', 'Amazon purchase', 'Uber ride', 'Bigbasket groceries', 'Recharge prepaid', 'Received salary'],
    'Amount': [150, 200, 300, 100, 50, 500]
}

# Create the DataFrame
df = pd.DataFrame(data)

# Strip any leading/trailing spaces in column names (if any)
df.columns = df.columns.str.strip()

# üîç Auto-categorize based on description keywords
def categorize_transaction(description):
    description = description.lower()
    if "swiggy" in description or "zomato" in description:
        return "Food"
    elif "amazon" in description or "flipkart" in description:
        return "Shopping"
    elif "uber" in description or "ola" in description:
        return "Transport"
    elif "bigbasket" in description:
        return "Groceries"
    elif "recharge" in description:
        return "Utilities"
    elif "cashback" in description:
        return "Rewards"
    elif "received" in description:
        return "Income"
    else:
        return "Others"

# Apply categorization function
df['Category'] = df['Description'].apply(categorize_transaction)

# --- 1. Data Exploration and Cleaning ---
# Check for missing values and duplicates
print("Missing values:", df.isnull().sum())
df = df.drop_duplicates()

# --- 2. Exploratory Data Analysis (EDA) ---
# Summary Statistics
print(df.describe())

# Visualizations
# Pie chart for category distribution
category_counts = df['Category'].value_counts()
category_counts.plot(kind='pie', autopct='%1.1f%%', startangle=90)
plt.title('Transaction Category Distribution')
plt.show()

# Histogram for Amount
sns.histplot(df['Amount'], kde=True)
plt.title('Amount Distribution')
plt.show()

# Correlation heatmap (only for numerical columns and encoded category)
# Encode the 'Category' column
le = LabelEncoder()
df['Category_encoded'] = le.fit_transform(df['Category'])

# Correlation heatmap (for numerical and encoded categorical columns)
sns.heatmap(df[['Amount', 'Category_encoded']].corr(), annot=True, cmap='coolwarm')
plt.show()

# --- 3. Feature Engineering ---
# If there are any timestamps, extract features (example with 'Date' column)
# df['Date'] = pd.to_datetime(df['Date'])
# df['Day_of_Week'] = df['Date'].dt.day_name()

# --- 4. Model Building (Optional) ---
# Prepare data for model (If prediction is desired)
X = df[['Amount']]  # Assuming Amount is the feature for prediction
y = df['Category']  # Target variable

# Split the data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train a RandomForest model
model = RandomForestClassifier()
model.fit(X_train, y_train)

# Predictions and Evaluation
y_pred = model.predict(X_test)

# Show classification report and confusion matrix
print(classification_report(y_test, y_pred))
print(confusion_matrix(y_test, y_pred))

# --- 5. Dashboard Creation (using Streamlit) ---
# Streamlit app (Run this code in a .py file using Streamlit)
st.title("Transaction Categorization Dashboard")

# Show the DataFrame
st.write(df.head())

# Pie chart for category distribution
st.write("Transaction Category Distribution")
st.bar_chart(category_counts)

# --- 6. Deployment ---
# To deploy using Streamlit, save this code in a .py file and run:
# streamlit run your_file_name.py